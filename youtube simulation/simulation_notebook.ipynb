{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Simulation (in notebook form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing environment packages and variables ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries/packages\n",
    "import random\n",
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Importing class files\n",
    "from agent import Agent\n",
    "from video import Video\n",
    "from activity import Activity\n",
    "from behavior_reference import BEHAVIOR_ARCHETYPE_PARAMETERS\n",
    "from behavior_reference import AGENT_ARCHETYPE_DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our macro values to be referenced later on\n",
    "NUM_VIDEOS = 10000;\n",
    "NUM_AGENTS = 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Video Objects ðŸŽ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate random view count (views range from 1 to 1 million)\n",
    "random_view_counts = []\n",
    "for i in range(NUM_VIDEOS):\n",
    "    r = random.randint(1, 1000000)\n",
    "    random_view_counts.append(r)\n",
    "\n",
    "\n",
    "# Generate random (unique) video ids\n",
    "# resultant random numbers list\n",
    "random_video_ids = []\n",
    "extremeness_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# traversing the loop 1000 times\n",
    "for i in range(NUM_VIDEOS):\n",
    "\n",
    "    # r=random.randint(1,100000)\n",
    "    # # checking whether the generated random number is not in the\n",
    "    # # randomList\n",
    "    # if r not in random_video_ids:\n",
    "    #     # appending the random number to the resultant list, if the condition is true\n",
    "        random_video_ids.append(i)\n",
    "\n",
    "\n",
    "# Generate random video length\n",
    "random_vid_lengths = []\n",
    "for i in range(NUM_VIDEOS):\n",
    "    r = random.randint(1, 80)\n",
    "    random_vid_lengths.append(r)\n",
    "\n",
    "# Generate random video extremeness\n",
    "random_extremeness = []\n",
    "for i in range(NUM_VIDEOS):\n",
    "    r = random.choice(extremeness_values)\n",
    "    random_extremeness.append(r)\n",
    "\n",
    "\n",
    "# Generate random number of thumbs up\n",
    "random_thumbs_up = []\n",
    "for i in range(NUM_VIDEOS):\n",
    "    r = random.randint(0, 50000)\n",
    "    random_thumbs_up.append(r)\n",
    "\n",
    "\n",
    "# Use the above arrays to create video objects\n",
    "all_videos = []\n",
    "for i in range(NUM_VIDEOS):   # create videos\n",
    "\n",
    "\n",
    "    # Grab the data points for the video\n",
    "    views = random_view_counts[i];\n",
    "    vid_id = random_video_ids[i];\n",
    "    length = random_vid_lengths[i];\n",
    "    extremeness = random_extremeness[i];\n",
    "    thumbs_up = random_thumbs_up[i];\n",
    "\n",
    "    # Create the video object\n",
    "    random_vid = Video(views, vid_id, length, extremeness, thumbs_up);\n",
    "\n",
    "    # Add the video object to our array of videos\n",
    "    all_videos.append(random_vid);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we can test that the video objects are created properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure this worked.\n",
    "\n",
    "print(\"Information for the first three videos:\");\n",
    "for i in range(3):\n",
    "    print(\"Views: \" + str(all_videos[i].views));\n",
    "    print(\"Video ID: \" + str(all_videos[i].vid_id));\n",
    "    # print(\"Length: \" + str(all_videos[i].length) +  \" minutes\");\n",
    "    print(\"Extremeness: \" + str(all_videos[i].extremeness));\n",
    "    # print(\"Thumbs up count: \" + str(all_videos[i].thumbs_up));\n",
    "    print(\"\");\n",
    "\n",
    "# # Let's test the watch function\n",
    "for i in range(10):\n",
    "    Activity.watch(all_videos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our Agents ðŸ‘©â€ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've generated the videos, we can generate our agents.\n",
    "# Let's start with 100 agents.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This means we will have the following archetype counts:\n",
    "\"\"\"\n",
    "AGENT_ARCHETYPE_DISTRIBUTION = {\n",
    "    \"progressive_activist\": .08,\n",
    "    \"traditional_liberal\": .11,\n",
    "    \"passive_liberal\": .15,\n",
    "    \"politically_disengaged\": .26,\n",
    "    \"moderate\": .15,\n",
    "    \"traditional_conservative\": .19,\n",
    "    \"devoted_conservative\": .06\n",
    "}    \n",
    "\n",
    "\"\"\"\n",
    "# So, 8 progressive activists, 11 traditional liberals, 15 passive liberals, 26 politically disengaged,\n",
    "# 15 moderates, 19 traditional conservatives, and 6 devoted conservatives.\n",
    "# Since we have 100 agents, their IDs can just be 1-100 in the order they are created.\n",
    "\n",
    "\n",
    "AGENT_ARCHETYPE_DISTRIBUTION = {\n",
    "    \"progressive_activist\": 0.08,\n",
    "    \"traditional_liberal\": 0.11,\n",
    "    \"passive_liberal\": 0.15,\n",
    "    \"politically_disengaged\": 0.26,\n",
    "    \"moderate\": 0.15,\n",
    "    \"traditional_conservative\": .19,\n",
    "    \"devoted_conservative\": 0.06\n",
    "}\n",
    "\n",
    "# Creating an array to hold our agents\n",
    "our_agents = [];\n",
    "\n",
    "id_counter = 0;\n",
    "# Generate the progressive activists (8)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"progressive_activist\"] * NUM_AGENTS)):    \n",
    "    our_agent = Agent(False, \"progressive_activist\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;\n",
    "\n",
    "# Generate the traditional liberals (11)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"traditional_liberal\"] * NUM_AGENTS)):\n",
    "    our_agent = Agent(False, \"traditional_liberal\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;\n",
    "\n",
    "# Generate the passive liberals (15)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"passive_liberal\"] * NUM_AGENTS)):\n",
    "    our_agent = Agent(False, \"passive_liberal\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;\n",
    "\n",
    "# Generate the politically disengaged (26)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"politically_disengaged\"] * NUM_AGENTS)):\n",
    "    our_agent = Agent(False, \"politically_disengaged\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;\n",
    "\n",
    "# Generate the moderates (15)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"moderate\"] * NUM_AGENTS)):\n",
    "    our_agent = Agent(False, \"moderate\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;\n",
    "\n",
    "# Generate the traditional conservatives (19)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"traditional_conservative\"] * NUM_AGENTS)):\n",
    "    our_agent = Agent(False, \"traditional_conservative\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;\n",
    "\n",
    "# Generate the devoted conservatives (6)\n",
    "for i in range(int(AGENT_ARCHETYPE_DISTRIBUTION[\"devoted_conservative\"] * NUM_AGENTS)):\n",
    "    our_agent = Agent(False, \"devoted_conservative\", id_counter, \"\");\n",
    "    our_agents.append(our_agent);\n",
    "    id_counter += 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can grab some data to test that these agents were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6,10):   # just a frew random agents versus showing the whole list\n",
    "    print(\"Agent ID: \" + str(our_agents[i].agent_id) + \"\\tArchetype: \" + our_agents[i].archetype);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating a Day ðŸ“…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what does an agent do in a given day?\n",
    "\n",
    "* Click on a video (they will be provided with a random video at start of day)\n",
    "    * Decide to watch the video if it aligns with their archetype parameters\n",
    "    * Actually watch the video\n",
    "    * Increment the video views\n",
    "    * Add the video length to their total time spent watching for today\n",
    "    * Flip a coin to determine if a thumbs up is left\n",
    "    * If total time spent watching for today is under their archetype's daily limit, find a new video.\n",
    "        * If over time, stop watching and end the day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to click on a video (agent will be provided with a random video at start of day)\n",
    "def suggest_video(video_list, num_videos):\n",
    "    random_video_id = random.randrange(num_videos);\n",
    "    return video_list[random_video_id];\n",
    "    \n",
    "\n",
    "# Function to print the attributes of a video object\n",
    "def display_vid_attrs(our_video):\n",
    "    rand_vid_views = our_video.views\n",
    "    rand_vid_id = our_video.vid_id\n",
    "    rand_vid_length = our_video.length\n",
    "    rand_vid_extremeness = our_video.extremeness\n",
    "    rand_vid_thumbsup = our_video.thumbs_up\n",
    "\n",
    "    print(\"Video ID: \" + str(rand_vid_id))\n",
    "    print(\"View Count: \" + str(rand_vid_views))\n",
    "    print(\"Length: \" + str(rand_vid_length) + \" minutes\")\n",
    "    print(\"Extremeness: \" + str(rand_vid_extremeness))\n",
    "    print(\"Thumbs Up Count: \" + str(rand_vid_thumbsup))\n",
    "\n",
    "\n",
    "# Function to display an agent's ID and archetype\n",
    "def display_agent(our_agent):\n",
    "    print(\"Agent ID: \" + str(our_agent.agent_id));\n",
    "    print(\"Archetype: \" + our_agent.archetype)\n",
    "\n",
    "\n",
    "# I copied this from https://www.geeksforgeeks.org/python-reversing-list/#\n",
    "def Reverse(lst):\n",
    "   new_lst = lst[::-1]\n",
    "   return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the video clicking\n",
    "suggested_video = suggest_video(all_videos, NUM_VIDEOS)\n",
    "display_vid_attrs(suggested_video)   \n",
    "\n",
    "length_total_temp = 0\n",
    "for i in range(NUM_VIDEOS):\n",
    "    l = all_videos[i].length\n",
    "    length_total_temp = length_total_temp + l\n",
    "\n",
    "length_total_temp = length_total_temp / NUM_VIDEOS\n",
    "\n",
    "print(length_total_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Daily Simulation Code\n",
    "\n",
    "The below code is where all of the watching actually happens for each agent.\n",
    "As of now, it only runs for one day, but making more days is as simple as just putting everything inside a  ```for i in range(NUM_DAYS)``` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_minutes_watched_today = 0   # how many minutes the agent has watched today\n",
    "total_vids_watched_today = 0  # how many videos the agent watched today\n",
    "agent_minutes_watched_today_array = []\n",
    "agent_vids_watched_today_array = []\n",
    "agent_extremeness_array = []\n",
    "\n",
    "'''\n",
    "   Change the ERROR below to DEBUG to trigger all of the print statements. \n",
    "   They're there mostly as tests from when I was debugging and such.\n",
    "   However, if you want to see \"real-time\" info from the simulation as it's running, feel free to uncomment them.\n",
    "'''\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "for i in range(NUM_AGENTS): # runs through the simulation for every agent in our array of agents\n",
    "    \n",
    "    # print(\"AGENT #\" + str(i))\n",
    "    # Establishing the values we need from our agent before any videos are watched\n",
    "    daily_agent = our_agents[i]\n",
    "    daily_agent_archetype = daily_agent.archetype\n",
    "\n",
    "    # These two need to be declared OUTSIDE of the run for each video.\n",
    "    # So, declare them within the day for a given agent, but OUTSIDE of the actual video selection checking loop.\n",
    "    # Otherwise, they don't actually get updated each time.\n",
    "    agent_minutes_watched_today = 0   # how many minutes the agent has watched today\n",
    "    agent_vids_watched_today = 0  # how many videos the agent watched today\n",
    "\n",
    "\n",
    "    activity_log = []  # ids of the videos the agent watched today\n",
    "\n",
    "\n",
    "    # Get the values for our agent's archetype\n",
    "\n",
    "    daily_agent_longest_vid = BEHAVIOR_ARCHETYPE_PARAMETERS[daily_agent_archetype][\"longest_vid_threshold\"]\n",
    "    daily_agent_yt_threshold = BEHAVIOR_ARCHETYPE_PARAMETERS[daily_agent_archetype][\"yt_time_threshold\"]\n",
    "    daily_agent_pol_aff = BEHAVIOR_ARCHETYPE_PARAMETERS[daily_agent_archetype][\"political_affiliation\"]\n",
    "    daily_agent_vid_extr = BEHAVIOR_ARCHETYPE_PARAMETERS[daily_agent_archetype][\"video_extremity\"]\n",
    "    daily_agent_pop_thresh = BEHAVIOR_ARCHETYPE_PARAMETERS[daily_agent_archetype][\"popularity_threshold\"]\n",
    "\n",
    "\n",
    "    time_left_check = True; # means we have enough time for the agent to keep watching videos\n",
    "\n",
    "\n",
    "    # This is where the agent is actually watching videos.\n",
    "    while(time_left_check == True):\n",
    "\n",
    "        suggested_video = suggest_video(all_videos, NUM_VIDEOS)\n",
    "\n",
    "        # display_agent(daily_agent)\n",
    "        # # print(\"\")\n",
    "        # display_vid_attrs(suggested_video)\n",
    "\n",
    "\n",
    "        # Compare our agent's thresholds to the attributes of the video\n",
    "\n",
    "        # print(\"\")\n",
    "\n",
    "        # Check minimum view threshold\n",
    "        if(suggested_video.views >= daily_agent_pop_thresh):\n",
    "            popularity_check = True\n",
    "            logging.debug(\"Video is popular enough.\")\n",
    "        else:\n",
    "            popularity_check = False\n",
    "            logging.debug(\"Video is not popular enough.\")\n",
    "\n",
    "        # Check agent's max viewing length\n",
    "        if(suggested_video.length < daily_agent_longest_vid):\n",
    "            length_check = True\n",
    "            logging.debug(\"Video is proper length.\")\n",
    "        else:\n",
    "            length_check = False\n",
    "            logging.debug(\"Video is too long.\")\n",
    "\n",
    "        # Check if watching this video would exceed the agent's daily threshold\n",
    "        potential_mins_watched = agent_minutes_watched_today + suggested_video.length\n",
    "        if(potential_mins_watched < daily_agent_yt_threshold):\n",
    "            time_left_check = True\n",
    "            logging.debug(\"Still time to watch this video.\")\n",
    "        else:\n",
    "            time_left_check = False\n",
    "            logging.debug(\"Not enough time left to watch this video.\")\n",
    "\n",
    "        # Check if this video is too extreme for the agent.\n",
    "\n",
    "\n",
    "    \n",
    "        # Left-leaning archetypes will watch anything at 0.5 and above. Right-leaning will watch 0.5 and below.\n",
    "        if(daily_agent_pol_aff == \"left\"):\n",
    "            # Will not watch anything under 0.5 extremeness\n",
    "            # If video extremeness is < 0.5 or higher than their extremeness value, do not watch.\n",
    "            if((suggested_video.extremeness < 0.5) or (suggested_video.extremeness > daily_agent_vid_extr)):\n",
    "                extreme_check = False\n",
    "                logging.debug(\"Video was too extreme.\")\n",
    "            else:\n",
    "                extreme_check = True\n",
    "                logging.debug(\"Video is within extremeness bounds (between 0.5 and agent's archetype value).\")\n",
    "        elif(daily_agent_pol_aff == \"right\"):\n",
    "            # Will not watch anything above 0.5 extremeness\n",
    "            # If video extremeness is > 0.5 or lower than their extremeness value (0.0 is extreme here), do not watch.\n",
    "            if((suggested_video.extremeness > 0.5) or (suggested_video.extremeness < daily_agent_vid_extr)):\n",
    "                extreme_check = False\n",
    "                logging.debug(\"Video was too extreme.\")\n",
    "            else:\n",
    "                extreme_check = True\n",
    "                logging.debug(\"Video is within extremeness bounds (between agent's archetype value and 0.5).\")\n",
    "        elif(daily_agent_pol_aff == \"middle\"):\n",
    "            # print(\"Extremeness:\" + str(suggested_video.extremeness))\n",
    "            # figuring this archetype is like middle of the road, they'll watch between 0.4 and 0.6\n",
    "            if((suggested_video.extremeness < 0.2) or (suggested_video.extremeness > 0.8)):\n",
    "                \n",
    "                extreme_check = False\n",
    "                logging.debug(\"Video was too extreme.\")\n",
    "            else:\n",
    "                extreme_check = True \n",
    "\n",
    "\n",
    "        # If all four checks pass, congrats! The agent will watch the video.\n",
    "        if(popularity_check and length_check and time_left_check and extreme_check):\n",
    "            Activity.watch(suggested_video)     # Agent actually watches the video.\n",
    "            agent_minutes_watched_today = agent_minutes_watched_today + suggested_video.length\n",
    "            agent_vids_watched_today = agent_vids_watched_today + 1\n",
    "            # print(\"\\nTotal minutes watched today is now \" + str(agent_minutes_watched_today) + \".\")\n",
    "    \n",
    "    # From below here, the agent is done watching videos for the day\n",
    "\n",
    "    total_minutes_watched_today = total_minutes_watched_today + agent_minutes_watched_today\n",
    "    total_vids_watched_today = total_vids_watched_today + agent_vids_watched_today\n",
    "\n",
    "    agent_minutes_watched_today_array.append(agent_minutes_watched_today)\n",
    "    agent_vids_watched_today_array.append(agent_vids_watched_today)\n",
    "    \n",
    "    \n",
    "    # This array needs to get the extremeness threshold of each agent\n",
    "    agent_extremeness_array.append(daily_agent_vid_extr)\n",
    "\n",
    "    logging.debug(\"\\nVideos watched today: \" + str(agent_vids_watched_today))\n",
    "    logging.debug(\"Minutes watched today: \" + str(agent_minutes_watched_today))\n",
    "\n",
    "\n",
    "\n",
    "print(\"TOTAL minutes watched today: \" + str(total_minutes_watched_today))\n",
    "print(\"TOTAL # of videos watched today: \" + str(total_vids_watched_today))\n",
    "\n",
    "# TODO for next time:\n",
    "# OH! Maybe do a while loop where while(time_left_check < daily_agent_yt_threshold), the whole getting a video and all the other checks thing happens.\n",
    "# Before this can be executed with other agents, however, you need to figure out extremeness for the middle ground agents.\n",
    "# Maybe if the extremeness is within 0.2 of the agent's value, the video can be watched. Idk.\n",
    "\n",
    "# Also, when you hopefully eventually get this whole thing working, use the Jupyter format to add lots of background and descriptive text.\n",
    "\n",
    "# Also also, use some of the graphing packages to make cute graphs of all the data across a given day.\n",
    "# Like maybe a big histogram of how many minutes each agent watched, or average watched/other stats by archetype\n",
    "\n",
    "\n",
    "# for i in range(NUM_AGENTS):\n",
    "#     print(agent_extremeness_array[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing Our Outputs\n",
    "\n",
    "What are some interesting data points we can (eventually) collect from the overall simulation?\n",
    "\n",
    "* How many total minutes + videos watched (already done)\n",
    "* Avg. minutes + videos watched per agent (also already done)\n",
    "* Avg. extremity of all videos that are watched\n",
    "* Different averages grouped by archetype\n",
    "* etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's graph each agent's extremeness with how much they watched per day.\n",
    "\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "# Reversing the arrays so extremenesses are in ascending order\n",
    "x = Reverse(agent_extremeness_array)\n",
    "y = Reverse(agent_minutes_watched_today_array)\n",
    "\n",
    "plt.scatter(x,y,color = 'forestgreen') # A bar chart\n",
    "plt.title('Minutes Watched Per Agent', fontsize = 18)\n",
    "plt.xlabel('Agent Extremeness')\n",
    "plt.ylabel('Minutes Watched')\n",
    "\n",
    "# defining display layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "plt.figure(figsize=(10,6))\n",
    "# fig.savefig('test2png.png', dpi=100)\n",
    "\n",
    "plt.text(50, numpy.nanmean(y) + 10, \"Average: \" + str(numpy.nanmean(y)), size=10, rotation=0.,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=dict(boxstyle=\"round\",\n",
    "                   ec='cornflowerblue',   # edge color: rbg values\n",
    "                   fc='lightsteelblue',   # fill color: rbg values\n",
    "                   )\n",
    "         )\n",
    "\n",
    "plt.show()  # WHY IS THIS GRAPH SO TINY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's graph each agent with how much they watched per day.\n",
    "# x axis = agents (0-199), y axis = minutes watched per agent\n",
    "\n",
    "x = numpy.arange(0,NUM_AGENTS)\n",
    "y = agent_minutes_watched_today_array\n",
    "\n",
    "plt.scatter(x,y, color = 'hotpink') # A bar chart\n",
    "plt.title('Minutes Watched Per Agent', fontsize = 18)\n",
    "plt.xlabel('Agents (0 - ' + str(NUM_AGENTS-1) + ')')\n",
    "plt.ylabel('Minutes Watched')\n",
    "plt.axhline(numpy.nanmean(y), linestyle = '--', color = 'cornflowerblue')\n",
    "\n",
    "# defining display layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.text(50, numpy.nanmean(y) + 10, \"Average: \" + str(numpy.nanmean(y)), size=10, rotation=0.,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=dict(boxstyle=\"round\",\n",
    "                   ec='cornflowerblue',   # edge color: rbg values\n",
    "                   fc='lightsteelblue',   # fill color: rbg values\n",
    "                   )\n",
    "         )\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's graph each agent with how many videos they watched per day.\n",
    "# x axis = agents (0-99), y axis = videos watched per agent\n",
    "\n",
    "x = numpy.arange(0,NUM_AGENTS)\n",
    "y = agent_vids_watched_today_array\n",
    "\n",
    "plt.scatter(x,y, color = 'cornflowerblue') # A bar chart\n",
    "plt.title('Videos Watched Per Agent', fontsize = 18)\n",
    "plt.xlabel('Agents (0 - ' + str(NUM_AGENTS-1) + ')')\n",
    "plt.ylabel('Videos Watched')\n",
    "plt.axhline(numpy.nanmean(y), linestyle = '--', color = 'hotpink')\n",
    "\n",
    "# defining display layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.text(50, numpy.nanmean(y) + 1, \"Average: \" + str(numpy.nanmean(y)), size=10, rotation=0.,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=dict(boxstyle=\"round\",\n",
    "                   ec='hotpink',   # edge color: rbg values\n",
    "                   fc='pink',   # fill color: rbg values\n",
    "                   )\n",
    "         )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's graph the above two side by side as a scatter plot.\n",
    "\n",
    "y1 = agent_minutes_watched_today_array\n",
    "y2 = agent_vids_watched_today_array\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "# using the twinx() for creating\n",
    "# another axes object for secondary y-Axis\n",
    "ax2 = ax.twinx()\n",
    "# creating a bar plot\n",
    "ax.scatter(x, y1, color = 'hotpink')\n",
    "ax2.scatter(x, y2, color = 'cornflowerblue')\n",
    "\n",
    "# giving labels to the axises\n",
    "# ax.set_xlabel('x-axis', color = 'r')\n",
    "ax.set_ylabel('Minutes Watched Per Agent', color = 'deeppink')\n",
    "\n",
    "# secondary y-axis label\n",
    "ax2.set_ylabel('Num. Videos Watcher Per Agent', color = 'b')\n",
    " \n",
    "# defining display layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.scatter(x=numpy.arange(0,NUM_AGENTS), y=agent_minutes_watched_today_array, color = 'hotpink')\n",
    "# plt.scatter(x=numpy.arange(0,NUM_AGENTS), y=agent_vids_watched_today_array, color = 'cornflowerblue') # use second y axis\n",
    "\n",
    "plt.title('Minutes Watched and Videos Watched Per Agent', fontsize=18)\n",
    "plt.xlabel('Agents (0 - ' + str(NUM_AGENTS-1) + ')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that looks confusing! Let's do the same thing, but with bars. That way, we can see the viewing habits for each agent more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's graph the above two side by side as a bar plot.\n",
    "\n",
    "y1 = agent_minutes_watched_today_array\n",
    "y2 = agent_vids_watched_today_array\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "# using the twinx() for creating\n",
    "# another axes object for secondary y-Axis\n",
    "ax2 = ax.twinx()\n",
    "# creating a bar plot\n",
    "ax.bar(x, y1, color = 'hotpink')\n",
    "ax2.bar(x, y2, color = 'cornflowerblue')\n",
    "\n",
    "# giving labels to the axises\n",
    "# ax.set_xlabel('x-axis', color = 'r')\n",
    "ax.set_ylabel('Minutes Watched Per Agent', color = 'deeppink')\n",
    "\n",
    "# secondary y-axis label\n",
    "ax2.set_ylabel('Num. Videos Watcher Per Agent', color = 'b')\n",
    " \n",
    "# defining display layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.scatter(x=numpy.arange(0,NUM_AGENTS), y=agent_minutes_watched_today_array, color = 'hotpink')\n",
    "# plt.scatter(x=numpy.arange(0,NUM_AGENTS), y=agent_vids_watched_today_array, color = 'cornflowerblue') # use second y axis\n",
    "\n",
    "plt.title('Minutes Watched and Videos Watched Per Agent', fontsize=18)\n",
    "plt.xlabel('Agents (0 - ' + str(NUM_AGENTS-1) + ')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo List ðŸ“\n",
    "\n",
    "* âœ…Get things to work with a different number of agents.\n",
    "* âœ…? Figure out why some agents aren't watching any videos at all. Are they really going through the whole list? Out of 10,000 videos, does not a single one really work for the middle ground people? Probably not.\n",
    "    * NOTE from 7/31: I'm still not sure what the issue is. It's not extremeness (I don't think), it's not the amount of views, and the issue is the same even when scaling up the number of videos. Thus, there's a chance it's something with how the videos are being generated, and whether a) every agent is seeing every video (which they probably aren't), or b) it's something with the agent's \"pickiness\" in terms of selecting a video\n",
    "    * NOTE from 8/1: okay what the HECK did I change. I changed something somewhere (I think it was the thresholds in the behavior_reference doc), but now for some reason just about every agent is watching a video. Literally what. I guess I won't complain because it's \"working\" now, but I have no clue if that was what fixed it. \n",
    "    * I THINK ITS MAKING EVERYONE A PROGRESSIVE ACTIVIST!!!! WHAT!!!!!!!!!!\n",
    "    * okay I got it\n",
    "* Actually get the recommendation function working (that's kind of the whole point of this). There's probably a lot you can graph from that---like little maps, almost, of what videos map to which (and their extremeness, etc.).\n",
    "    * On that note, actually figure out what links two videos. Is it within a certain extremeness value? Or what?\n",
    "* âœ…Think about research questions you're aiming to answer---how are you going to examine and tell that story? \n",
    "    * e.g. do more extreme agents get channeled to more extreme videos? what graph would show that?\n",
    "    * Does the recommendation system make users watch more extreme videos than what they would watch without the system? Can we compare side-by-side the video extremeness for agents with and without the system?\n",
    "    * If the recommendation system does, in fact, channel viewers towards more extreme content, in what ways can we mitigate or reduce these effects?\n",
    "    * Do extreme videos continually beget more extreme videos? i.e. is there a \"rabbit hole\" effect where an agent's watched videos become more and more extreme? Can we use a graph to make a map of which videos (and their extremeness) recommend each other?\n",
    "\n",
    "* âœ…Look at package -- ```logging``` (can automate print statements and such) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Recommendation Algorithm\n",
    "\n",
    "Okay, so. Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems (RecSys '16). Association for Computing Machinery, New York, NY, USA, 191â€“198. https://doi.org/10.1145/2959100.2959190 is a paper from Google that outlines how their recommendation system works. Fantastic hearing it right from them. In short, they use two very large neural networks: one to narrow down the massive corpus of YouTube videos into a couple hundred that are relevant to the user, and one to rank these aforementioned videos in order of relevance to the user (which is then what's recommended). The narrowing down part isn't too exciting; there's a nice fancy equation they give for it. What I'm more concerned about is the ranking part. The videos are ranked by using logistic regression to assign a \"score\" to each video based on several hundred \"features\" about the user and video in question. This kind of bothers me. The paper lists some of these \"incredibly robust\" features (whether the user is logged in, their previous search queries, user's past history with the video's channel), but what are the rest of them??? I found another article (https://thecityvoice.org/2020/05/14/google-wants-to-know-your-gender-heres-why/) that discusses how Google's ad service determines your gender of its own accord and uses this determination in its marketing, which may have me predisposed to being suspicious of these supposedly robust features, but I only found that in the first place because the paper mentions that gender is considered as a factor (and on a [0,1] scale). So. I also didn't get any answer on how exactly videos relate to each other--I wasn't able to tell in how much isolation the neural network part happens from the actual video being watched, but it seems the video currently being watched only impacts which videos are narrowed down from the corpus (since it's in that equation).\n",
    "\n",
    "### How My Algorithm Has to Work\n",
    "\n",
    "After reading that paper this almost feels like working for the enemy. I guess I have to create a similar \"score-assigning\" ranking system, but what will my incredibly robust features be? In this case, it's probably extremeness, but is that enough? Enough for what--getting a larger holistic picture of the recommendation system, or how particularly the recommendation system uses extremeness? I should also look into logistic regression--I'm sure Scikit or some other library I already have imported here has some flavor of it that I can use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
